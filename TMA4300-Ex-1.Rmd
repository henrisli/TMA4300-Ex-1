--- 
title: 'TMA4300 Computer Intensive Statistical Methods Exercise 1, Spring 2019'
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
    toc_float: yes
date: "`r format(Sys.time(), '%d.%m.%Y')`"
subtitle: 'Group members: Henrik Syversveen Lie, Mikal Stapnes (SKRIVE STUDENTNUMMER I STEDET??)'
---


```{r setup, include = FALSE}
library(formatR)
showsol <- FALSE
library(knitr)
opts_chunk$set(tidy.opts = list(width.cutoff = 68), tidy = TRUE, warning = FALSE, error = FALSE, message = FALSE, echo = TRUE)
```

# Problem A: Stochastic simulation by the probability integral transform and bivariate techniques

## 1.
We make a function that draws $n$ random numbers from an exponential distribution with parameter $\lambda$. If $u$ is uniformly distributed between 0 and 1, $u\sim U(0,1)$, then $x=-\log(u)/\lambda$ will be exponentially distributed with parameter $\lambda$, or $x\sim \text{Exp}(\lambda)$.
```{r, echo = T, eval = T}
library(ggplot2)
exponential<- function(lambda, n){
  u = runif(n)
  x = -1/lambda*log(u)
  return(x)
}
```
Then we want to check if this function is correct. To do this, we check a few things. Firstly we compare the mean and variance of a sample drawn from our function with the theoretical mean and variance. The theoretical mean and variance of a exponential distribution are $\mu = 1/\lambda$ and $\sigma^2 = 1/\lambda^2$. We draw a sample with $\lambda = 4.300$ and compare:
```{r, echo = T, eval = T}
n = 10000
lambda = 4.300
y = rexp(n, lambda)
x = exponential(lambda,n)
cat('Theoretical mean: ', 1/lambda,' Computed mean: ', mean(x),'\n')
cat('Theoretical variance: ', 1/lambda^2, ' Computed variance: ', var(x))
```
We see that they are almost the same. Finally we make two plots. The first is a histogram comparison of our function and the R function `rexp()`, which draws random samples from an exponential distribution. The second plot is a histogram of our random sample compared with the theoretical exponential distribution.
```{r, echo = T, eval = T}
rfunc = data.frame(value = y)
ourfunc = data.frame(value = x)
rfunc$type = 'R function'
ourfunc$type = 'Our function'
df = rbind(rfunc,ourfunc)
ggplot(df, aes(value, fill = type)) + 
   geom_histogram(alpha = 0.5, aes(y = ..density..), binwidth = 0.05, position = 'identity') + ggtitle("Our function vs. R function densities")
df2 <- data.frame(theo=seq(0,max(x),length.out=n), value=x)
h <- ggplot(df2, aes(x = value))
h <- h + geom_histogram(aes(y = ..density..), binwidth=0.05) +stat_function(fun=dexp,geom = "line",size=1.6,col="red",args = (mean=lambda))
h <- h + ggtitle("Our function vs. theoretical density")
h
```

## 2. a)
We first note that the normalizing constant will be $c=\frac{e\alpha}{e+\alpha}$, which can be found by solving $$\int_0^{\infty} g(x)dx = 1.$$

We find the cumulative distribution by noting that $F_X(x) = P(X\leq x)$, which gives 
$$F_X(x) = \int_0^x g(\xi)d\xi = \begin{cases} \int_0^x c\xi^{\alpha-1}d\xi = \frac{cx^{\alpha}}{\alpha}, \quad &0\leq x\leq 1,\\ \frac{c}{\alpha}+\int_1^x c\exp(-\xi)d\xi = \frac{c}{\alpha}+\frac{c}{e}-c\exp(-x), \quad &1\leq x,\\0, &\text{otherwise}.\end{cases}$$
With the inverse
$$F_X^{-1}(u) = \begin{cases} \frac{\alpha}{c}u, \quad 0 \leq u<\frac{c}{\alpha} \\
-ln(\frac{1}{\alpha} + \frac{1}{e} - \frac{u}{c}), \quad \frac{c}{\alpha} \leq u \leq 1,
\end{cases}
$$
which we can use to sample from $f(x)$. We confirm this by sampling from $u \sim U[0, 1]$, computing the inverse $X = F^{-1}_X(u)$ and plotting a histogram over the results.

```{r}
f_A2 = function(c, x, alpha){
  result = vector(mode='double', length = length(x))
  result[x<1.] = sapply(x[x<1.], function(x) c*x^(alpha - 1), USE.NAMES=F)
  result[x>=1.] = sapply(x[x>=1.], function(x) c*exp(-x), USE.NAMES=F)
  return(result)
}

F_inv = function(c, u, alpha){
  result = vector(length = length(u))
  result[u < c/alpha] = (alpha/c * u[u < c/alpha])^(1/alpha)
  result[u >= c/alpha] = -log(1/alpha + exp(-1) - u[u >= c/alpha]/c)
  return(result)
}

alpha = 2
c = exp(1)*alpha / (exp(1) + alpha)
usamples = runif(n=1000000)
xsamples = F_inv(c, usamples, alpha)
histogram = hist(xsamples, breaks=40, probability=T, plot=F)

x_val = linspace(0, max(xsamples), 100)

plot(histogram$mids, histogram$density, ylim=c(0., 1.), col="blue", xlab = "x", ylab="P(x)")
lines(x_val, f_A2(c, x_val, alpha), type='l', col="red")
legend(x="topright", .95, legend=c("Analytic", "Inverse sampling"), col=c('red', 'blue'), lty=1, cex=0.8)
```

We see that the analytical expression overlaps perfectly with the histogram over the samples, confirming the our algorithm is correct. 

# Problem B: The gamma distribution

We can sample from the gamma distribution 

$$ f(x) = \begin{cases}
\frac{1}{\Gamma(\alpha)}x^{\alpha-1}e^{-x} \\
0, \quad \text{otherwise}. \\
\end{cases} $$



using the distribution found in A.2 as a proposal distribution. We can do this because the A.2 distribution is nonzero at all points where $f(x)$ is nonzero

```{r}
library(pracma)

x = linspace(0, 10, 100)
y_gamma = dgamma(x, shape=1, rate=1)
y_prop = f_A2(1, x, 1)


plot1 = plot(x, y_gamma, col='red', type='l', ylab="", ylim = c(0., 1.))
lines(x, y_prop, type='l', col='blue')
legend(x="topright", .95, legend=c("Gamma", "Proposal"), col=c('red', 'blue'), lty=1, cex=0.8)
```
We note that the acceptance probabiltiy, P_{accept}, 

$$P_{accept} = \int_0^{\infty} P_{unif}(U \leq \frac{f(x)}{c g(x)} ) P_{prop}(X = x) \\
 = \int_0^{\infty} \frac{f(x)}{c g(x)} g(x) = c^{-1}$$

We sample from $X \sim g(x)$ and $U \sim u[0, 1]$, and accept the sample $x$ if $u \leq \frac{f(x)}{c g(x)}$.

```{r}

c = 1
alpha = 1
rate = 1

f_A2 = function(c, x, alpha){
  result = vector(mode='double', length = length(x))
  result[x<1.] = sapply(x[x<1.], function(x) c*x^(alpha - 1), USE.NAMES=F)
  #print(x[x>=1.])
  if (!all(x<1.)){
    #print(x[x>=1.])
    result[x>=1.] = sapply(x[x>=1.], function(x) c*exp(-x), USE.NAMES=F)
  }
  return(result)
}

sample_gamma = function(n=1000){
  uniform1 = runif(n)
  uniform2 = runif(n)
  x = F_inv(c, uniform1, alpha)
  probs = dgamma(x, alpha, rate) / (c * f_A2(c, x, alpha))
  return(x[uniform2 <= probs])
}

g_samples = sample_gamma(10000)

histogram2 = hist(g_samples, breaks=10, probability=T, plot=T)


FÃ…R IKKJE MED HALEN HER FOR SOME REASON

x_val = linspace(0, 5, 100)
plot(histogram2$mids, histogram2$density, ylim=c(0., 1.0))
lines(x_val, dgamma(x_val, alpha, rate), type='l')


```

=======
